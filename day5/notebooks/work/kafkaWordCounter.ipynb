{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9200f7a8-ea5b-48e4-8c36-3b331aaf7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from IPython.display import display, display_pretty, clear_output, JSON\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.sql.session.timeZone\", \"Asia/Seoul\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# 노트북에서 테이블 형태로 데이터 프레임 출력을 위한 설정을 합니다\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # display enabled\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 100) # display output columns size\n",
    "\n",
    "# 공통 데이터 위치\n",
    "home_jovyan = \"/home/jovyan\"\n",
    "work_data = f\"{home_jovyan}/work/data\"\n",
    "work_dir=!pwd\n",
    "work_dir = work_dir[0]\n",
    "\n",
    "# 로컬 환경 최적화\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5) # the number of partitions to use when shuffling data for joins or aggregations.\n",
    "spark.conf.set(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\")\n",
    "\n",
    "# 현재 기동된 스파크 애플리케이션의 포트를 확인하기 위해 스파크 정보를 출력합니다\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36676814-34ce-4033-a012-e01ecaab063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트림 테이블을 주기적으로 조회하는 함수 (name: 이름, sql: Spark SQL, iterations: 반복횟수, sleep_secs: 인터벌)\n",
    "def displayStream(name, sql, iterations, sleep_secs):\n",
    "    from time import sleep\n",
    "    i = 1\n",
    "    for x in range(iterations):\n",
    "        clear_output(wait=True)              # 출력 Cell 을 지웁니다\n",
    "        display('[' + name + '] Iteration: '+str(i)+', Query: '+sql)\n",
    "        display(spark.sql(sql))              # Spark SQL 을 수행합니다\n",
    "        sleep(sleep_secs)                    # sleep_secs 초 만큼 대기합니다\n",
    "        i += 1\n",
    "\n",
    "# 스트림 쿼리의 상태를 주기적으로 조회하는 함수 (name: 이름, query: Streaming Query, iterations: 반복횟수, sleep_secs: 인터벌)\n",
    "def displayStatus(name, query, iterations, sleep_secs):\n",
    "    from time import sleep\n",
    "    i = 1\n",
    "    for x in range(iterations):\n",
    "        clear_output(wait=True)      # Output Cell 의 내용을 지웁니다\n",
    "        display('[' + name + '] Iteration: '+str(i)+', Status: '+query.status['message'])\n",
    "        display(query.lastProgress)  # 마지막 수행된 쿼리의 상태를 출력합니다\n",
    "        sleep(sleep_secs)            # 지정된 시간(초)을 대기합니다\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a5904-333d-4e31-b9f8-18f42a4d4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafkaReader = (\n",
    "    spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka:9093\")\n",
    "  .option(\"subscribe\", \"movies\")\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .load()\n",
    ")\n",
    "\n",
    "kafkaReader.printSchema()\n",
    "\n",
    "kafkaSchema = (\n",
    "    StructType()\n",
    "    .add(StructField(\"movie\", StringType()))\n",
    "    .add(StructField(\"title\", StringType()))\n",
    "    .add(StructField(\"title_eng\", StringType()))\n",
    "    .add(StructField(\"year\", IntegerType()))\n",
    "    .add(StructField(\"grade\", StringType()))\n",
    "    .add(StructField(\"time\", StringType()))\n",
    "    .add(StructField(\"timestamp\", StringType()))\n",
    ")\n",
    "\n",
    "kafkaSelector = (\n",
    "    kafkaReader\n",
    "    .select(\n",
    "        col(\"key\").cast(\"string\"),\n",
    "        from_json(col(\"value\").cast(\"string\"), kafkaSchema).alias(\"movies\")\n",
    "    )\n",
    "    .selectExpr(\"movies.movie as key\", \"to_json(struct(movies.*)) as value\")\n",
    ")\n",
    "\n",
    "kafkaSelector.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114147aa-b7eb-4032-89be-ef0ca9eb6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카프카로 다시 저장\n",
    "queryName = \"kafkaSink\"\n",
    "kafkaWriter = (\n",
    "    kafkaSelector.select(\"key\", \"value\")\n",
    "    .writeStream\n",
    "    .queryName(queryName)\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9093\")\n",
    "    .option(\"topic\", \"korean_movies\")\n",
    "    .outputMode(\"append\")\n",
    ")\n",
    "\n",
    "checkpointLocation = f\"{work_dir}/tmp/{queryName}\"\n",
    "!rm -rf $checkpointLocation\n",
    "\n",
    "kafkaTrigger = (\n",
    "    kafkaWriter\n",
    "    .trigger(processingTime=\"5 seconds\")\n",
    "    .option(\"checkpointLocation\", checkpointLocation)\n",
    ")\n",
    "\n",
    "kafkaQuery = kafkaTrigger.start()\n",
    "displayStatus(queryName, kafkaQuery, 1000, 10)\n",
    "kafkaQuery.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44f78d-41e8-460e-8513-0000cc6ff02f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
