{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스파크 스트리밍 실습 1교시 - Spark Streaming Introduction\n",
    "\n",
    "> 스파크 스트리밍의 애플리케이션 예제를 통해서 어떻게 운영 및 수행 되는지를 학습합니다. \n",
    "\n",
    "### 목차\n",
    "* [1. 소스 스키마 읽기](#1.-소스-스키마-읽기)\n",
    "* [2. 소스 읽기 코드 작성](#2.-소스-읽기-코드-작성)\n",
    "* [3. 변환 코드 작성](#3.-변환-코드-작성)\n",
    "* [4. 싱크 코드 작성](#4.-싱크-코드-작성)\n",
    "* [5. 트리거 코드 작성](#5.-트리거-코드-작성)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/07 01:39:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c6c145fcf635:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f55883addc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from IPython.display import display, display_pretty, clear_output, JSON\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.sql.session.timeZone\", \"Asia/Seoul\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# 노트북에서 테이블 형태로 데이터 프레임 출력을 위한 설정을 합니다\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # display enabled\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 100) # display output columns size\n",
    "\n",
    "# 공통 데이터 위치\n",
    "home_jovyan = \"/home/jovyan\"\n",
    "work_data = f\"{home_jovyan}/work/data\"\n",
    "work_dir=!pwd\n",
    "work_dir = work_dir[0]\n",
    "\n",
    "# 로컬 환경 최적화\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5) # the number of partitions to use when shuffling data for joins or aggregations.\n",
    "spark.conf.set(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 소스 스키마 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Arrival_Time</th><th>Creation_Time</th><th>Device</th><th>Index</th><th>Model</th><th>User</th><th>gt</th><th>x</th><th>y</th><th>z</th></tr>\n",
       "<tr><td>1424686735090</td><td>1424686733090638193</td><td>nexus4_1</td><td>18</td><td>nexus4</td><td>g</td><td>stand</td><td>3.356934E-4</td><td>-5.645752E-4</td><td>-0.018814087</td></tr>\n",
       "<tr><td>1424686735292</td><td>1424688581345918092</td><td>nexus4_2</td><td>66</td><td>nexus4</td><td>g</td><td>stand</td><td>-0.005722046</td><td>0.029083252</td><td>0.005569458</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
       "| Arrival_Time|      Creation_Time|  Device|Index| Model|User|   gt|           x|           y|           z|\n",
       "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
       "|1424686735090|1424686733090638193|nexus4_1|   18|nexus4|   g|stand| 3.356934E-4|-5.645752E-4|-0.018814087|\n",
       "|1424686735292|1424688581345918092|nexus4_2|   66|nexus4|   g|stand|-0.005722046| 0.029083252| 0.005569458|\n",
       "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Arrival_Time: long (nullable = true)\n",
      " |-- Creation_Time: long (nullable = true)\n",
      " |-- Device: string (nullable = true)\n",
      " |-- Index: long (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- gt: string (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 소스 스키마\n",
    "activityPath = f\"{work_data}/activity-data\"\n",
    "activityData = spark.read.option(\"inferSchema\", \"true\").json(activityPath)\n",
    "display(activityData.limit(2))\n",
    "activityData.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 소스 읽기 코드 작성\n",
    "\n",
    "> 예제에서는 json 파일을 소스로 사용했으며, `format(\"json\").load(path)` 대신 `json(path)` 를 사용해도 동일합니다\n",
    "\n",
    "#### [Input Sources](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#input-sources)\n",
    "| 포맷 | 특징 | 옵션 |\n",
    "| --- | --- | --- |\n",
    "| File Source | parquet, json, csv 등의 파일의 읽기 | .option(\"path\", \"path/to/read\"), 콤마 구분자로 `여러 경로를 지정할 수 없습니다` |\n",
    "| Kafka Source | kafka 읽기를 위한 소스 | .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\") 옵션을 통해 카프카 클러스터를 지정하고, .option(\"topic\", \"updates\") 옵션을 통해 토픽을 지정합니다 |\n",
    "| Socket Source | 소켓 서버로부터 스트리밍을 읽기 위한 소스 | .option(\"host\", \"localhost\"), .option(\"port\", 9999) 옵션을 통해 소켓서버를 지정합니다, includeTimestamp 옵션으로 `value`, `timestamp` 지원 |\n",
    "| Rate Source | 트리밍 디버깅을 위한 포맷이며, 콘솔로 바로 출력합니다 | Debug Only |\n",
    "\n",
    "* File Source Options\n",
    "  - maxFilesPerTrigger : maximum number of new files to be considered in every trigger\n",
    "  - latestFirst : whether to process the latest new files first, useful when there is a large backlog of files (default: false)\n",
    "  - maxFileAge : A mapping from a file that we have processed to some timestamp it was last modified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소스 읽기\n",
    "activitySchema = activityData.schema\n",
    "activityReader = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .schema(activitySchema)\n",
    "    .format(\"json\")\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .load(activityPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 변환 코드 작성\n",
    "\n",
    "> '구조화된 스트리밍' 에서는 점진적으로 수행 가능한 데이터프레임 연산만 지원하며, 이를 크게 '스테이트리스', '스테이트풀' 연산이라 합니다\n",
    "\n",
    "> 한 번에 모든 '논리적 계획'을 '물리적계획'으로 변환하는 배치 처리와 다르게, 연속적인 실행의 계획을 생성하는 역할을 수행합니다. 매 실행은 '마이크로배치' 작업을 말하며, **작업과 작업 간의 중간 결과물**을 스트리밍 **상태**라고 말합니다.\n",
    "\n",
    "#### `스테이트리스 (Stateless)` 데이터 변환\n",
    "  - 모든 프로젝션 연산(select, explode, map, flatMap) 들과 셀렉트 연산(filter, where) 들은 이전 로우의 상태와 무관한 '스테이트리스' 연산자들입니다\n",
    "  - 이러한 '스테이트리스' 연산자 들만 append, update 출력 모드를 지원합니다.\n",
    "    - '중간결과물인 상태'가 없다는 의미는 현재 로우에만 영향 및 의존성을 가진다는 말이므로, append 모드로 동작 하더라도 중복문제가 생기지 않습니다\n",
    "  - 반면에 complete 모드를 지원하지 않습니다,\n",
    "    - 이는 매 새로운 데이터를 반복적으로 처리하는 것은 비용적으로 크기 때문입니다.\n",
    "\n",
    "#### `스테이트풀 (Stateful)` 데이터 변환\n",
    "  - DataFrame.groupBy().count() 스트리밍의 시작부터 발생하는 레코드의 수를 나타내는데, 이전 '마이크로배치'의 빈도수를 저장하고 있어야 하며 이를 '상태'라고 부릅니다\n",
    "  - 상태저장이 어떻게 동작하는 지 테스트 하는데, 파일 스트림을 통한 연속적인 테스트는 어렵다는 사실을 알 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변환\n",
    "activityCounter = activityReader.groupBy(\"gt\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 싱크 코드 작성\n",
    "\n",
    "> 예제에서는 디버깅을 위한 console 포맷과 update 모드를 사용했습니다\n",
    "\n",
    "#### [Output Sinks](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#output-sinks)\n",
    "| 포맷 | 특징 | 옵션 |\n",
    "| --- | --- | --- |\n",
    "| File Sink | parquet, json, csv 등의 파일을 저장 | .option(\"path\", \"path/to/write\") |\n",
    "| Kafka Sink | kafka 저장을 위한 싱크 | .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\") 옵션을 통해 카프카 클러스터를 지정하고, .option(\"topic\", \"updates\") 옵션을 통해 토픽을 지정합니다 |\n",
    "| Foreach Sink | 스트리밍 싱크를 지원하지 않는 경우에도 임의의 연산을 수행을 통해 저장할 수 있는 옵션 | - |\n",
    "| Console Sink | 트리밍 디버깅을 위한 포맷이며, 콘솔로 바로 출력합니다 | Debug Only |\n",
    "| Memory Sink | 스트리밍 디버깅을 위한 포매싱며, 임의의 테이블로 출력합니다 | Debug Only, .queryName(\"tableName\") 옵션을 통해 테이블 이름을 지정합니다 |\n",
    "\n",
    "\n",
    "#### [Output Modes](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#output-modes)\n",
    "\n",
    "| 출력 모드 | 특징 | 옵션 |\n",
    "| --- | --- | --- |\n",
    "| Append Mode | 신규로 발생한 로우의 추가만 가능한 모드이며, 기존 결과 테이블에 저장된 로우들은 변경되지 않습니다 | .option(\"path\", \"path/to/file\") |\n",
    "| Update Mode | 마지막 트리거 이후에 발생한 모든 로우가 외부 저장소에 변경되는 모드 | MySQL 과 같이 업데이트를 지원하는 싱크 저장소만 사용할 수 있으며, 쿼리가 Aggregation 을 포함하지 않는다면 Complete 와 동일하게 동작합니다 |\n",
    "| Complete Mode | 매번 결과 테이블 전체를 갱신하는 모드이며 | 모든 로우를 매번 출력할 만큼 충분히 결과가 작은 경우에 사용할 수 있습니다 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 싱크 쓰기\n",
    "queryName = \"activity_count\"\n",
    "checkpointLocation = f\"{work_dir}/tmp/{queryName}\"\n",
    "activityWriter = (\n",
    "    activityCounter\n",
    "    .writeStream\n",
    "    .queryName(queryName)\n",
    "    .format(\"console\")\n",
    "    .outputMode(\"complete\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 트리거 코드 작성\n",
    "\n",
    "#### [Triggers](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#triggers)\n",
    "\n",
    "| 트리거 유형 | 특징 | 옵션 |\n",
    "| --- | --- | --- |\n",
    "| Unspecified (Default) | 지정하지 않은 경우는 마이크로 배치 모드로 동작하며, 이전 마이크로 배치가 종료하는 즉시 다음 작업이 트리거 됩니다. | - |\n",
    "| Fixed interval micro-batches | 제공되는 인터벌에 따라 동작하지만, 이전 작업이 인터벌 보다 늦게 종료되는 경우, 종료 즉시 다음 작업이 트리거 됩니다 | 새로운 작업이 없는 경우 트리거링 되지 않습니다 |\n",
    "| One-time micro-batch | 처음 한 번만 수행됩니다 | 스케줄러 등을 통해 주기적으로 스트리밍 서비스를 수행할 때에 유용합니다 |\n",
    "| Continuous with fixed checkpoint interval (experimental) | 마이크로 배치가 아니라 Continuous 모드로 동작합니다 | [Continuous Processing](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#continuous-processing) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트리거\n",
    "activityTrigger = (\n",
    "    activityWriter\n",
    "    .trigger(processingTime=\"1 second\")\n",
    "    .option(\"checkpointLocation\", checkpointLocation)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 애플리케이션 기동 및 종료\n",
    "\n",
    "* 기동 작업을 재수행 한다고 하더라도, 과거에 체크포인트에 저장된 값을 통해 기동되기 때문에 변화가 없습니다\n",
    "* 다시 재기동 하기 위해서는 체크포인트를 삭제하고, 처음부터 기동하여야 합니다\n",
    "```bash\n",
    "# 임시파일 삭제\n",
    "!rm -rf $checkpointLocation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/21 14:43:58 WARN OffsetSeqMetadata: Conf 'spark.sql.streaming.stateStore.compression.codec' was not found in the offset log, using default value 'lz4'\n",
      "21/08/21 14:43:59 WARN HDFSBackedStateStoreProvider: The state for version 31 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.\n",
      "21/08/21 14:43:59 WARN HDFSBackedStateStoreProvider: The state for version 31 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.\n",
      "21/08/21 14:43:59 WARN HDFSBackedStateStoreProvider: The state for version 31 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.\n",
      "21/08/21 14:43:59 WARN HDFSBackedStateStoreProvider: The state for version 31 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.\n",
      "21/08/21 14:43:59 WARN HDFSBackedStateStoreProvider: The state for version 31 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 31\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|393885|\n",
      "|     stand|364315|\n",
      "|stairsdown|299609|\n",
      "|      walk|424161|\n",
      "|  stairsup|334659|\n",
      "|      null|334282|\n",
      "|      bike|345483|\n",
      "+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/21 14:44:00 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 1000 milliseconds, but spent 1718 milliseconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 32\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|406192|\n",
      "|     stand|375701|\n",
      "|stairsdown|308970|\n",
      "|      walk|437416|\n",
      "|  stairsup|345116|\n",
      "|      null|344730|\n",
      "|      bike|356281|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 33\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|418500|\n",
      "|     stand|387087|\n",
      "|stairsdown|318333|\n",
      "|      walk|450672|\n",
      "|  stairsup|355571|\n",
      "|      null|355177|\n",
      "|      bike|367077|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 34\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|430808|\n",
      "|     stand|398473|\n",
      "|stairsdown|327693|\n",
      "|      walk|463928|\n",
      "|  stairsup|366029|\n",
      "|      null|365623|\n",
      "|      bike|377874|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 35\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|443116|\n",
      "|     stand|409857|\n",
      "|stairsdown|337052|\n",
      "|      walk|477184|\n",
      "|  stairsup|376490|\n",
      "|      null|376069|\n",
      "|      bike|388671|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 36\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|455424|\n",
      "|     stand|421241|\n",
      "|stairsdown|346412|\n",
      "|      walk|490440|\n",
      "|  stairsup|386951|\n",
      "|      null|386515|\n",
      "|      bike|399468|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 37\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|467732|\n",
      "|     stand|432625|\n",
      "|stairsdown|355773|\n",
      "|      walk|503696|\n",
      "|  stairsup|397412|\n",
      "|      null|396960|\n",
      "|      bike|410266|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 38\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|480040|\n",
      "|     stand|444009|\n",
      "|stairsdown|365134|\n",
      "|      walk|516952|\n",
      "|  stairsup|407875|\n",
      "|      null|407405|\n",
      "|      bike|421063|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 39\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|492348|\n",
      "|     stand|455392|\n",
      "|stairsdown|374497|\n",
      "|      walk|530207|\n",
      "|  stairsup|418336|\n",
      "|      null|417852|\n",
      "|      bike|431860|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 40\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|504656|\n",
      "|     stand|466775|\n",
      "|stairsdown|383858|\n",
      "|      walk|543462|\n",
      "|  stairsup|428799|\n",
      "|      null|428299|\n",
      "|      bike|442657|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 41\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|516964|\n",
      "|     stand|478158|\n",
      "|stairsdown|393220|\n",
      "|      walk|556717|\n",
      "|  stairsup|439261|\n",
      "|      null|438746|\n",
      "|      bike|453454|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 42\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|529271|\n",
      "|     stand|489542|\n",
      "|stairsdown|402586|\n",
      "|      walk|569972|\n",
      "|  stairsup|449719|\n",
      "|      null|449194|\n",
      "|      bike|464250|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 43\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|541579|\n",
      "|     stand|500926|\n",
      "|stairsdown|411953|\n",
      "|      walk|583227|\n",
      "|  stairsup|460176|\n",
      "|      null|459641|\n",
      "|      bike|475046|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 44\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|553887|\n",
      "|     stand|512310|\n",
      "|stairsdown|421321|\n",
      "|      walk|596482|\n",
      "|  stairsup|470632|\n",
      "|      null|470088|\n",
      "|      bike|485842|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 45\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|566195|\n",
      "|     stand|523695|\n",
      "|stairsdown|430690|\n",
      "|      walk|609737|\n",
      "|  stairsup|481088|\n",
      "|      null|480534|\n",
      "|      bike|496637|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 46\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|578503|\n",
      "|     stand|535080|\n",
      "|stairsdown|440057|\n",
      "|      walk|622991|\n",
      "|  stairsup|491547|\n",
      "|      null|490979|\n",
      "|      bike|507432|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 47\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|590814|\n",
      "|     stand|546465|\n",
      "|stairsdown|449425|\n",
      "|      walk|636245|\n",
      "|  stairsup|502004|\n",
      "|      null|501422|\n",
      "|      bike|518227|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 48\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|603125|\n",
      "|     stand|557851|\n",
      "|stairsdown|458790|\n",
      "|      walk|649498|\n",
      "|  stairsup|512462|\n",
      "|      null|511868|\n",
      "|      bike|529021|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 49\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|615436|\n",
      "|     stand|569237|\n",
      "|stairsdown|468153|\n",
      "|      walk|662751|\n",
      "|  stairsup|522921|\n",
      "|      null|522314|\n",
      "|      bike|539816|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 50\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|627747|\n",
      "|     stand|580623|\n",
      "|stairsdown|477518|\n",
      "|      walk|676004|\n",
      "|  stairsup|533378|\n",
      "|      null|532760|\n",
      "|      bike|550611|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 51\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|640058|\n",
      "|     stand|592009|\n",
      "|stairsdown|486881|\n",
      "|      walk|689257|\n",
      "|  stairsup|543835|\n",
      "|      null|543207|\n",
      "|      bike|561406|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 52\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|652369|\n",
      "|     stand|603394|\n",
      "|stairsdown|496243|\n",
      "|      walk|702511|\n",
      "|  stairsup|554293|\n",
      "|      null|553653|\n",
      "|      bike|572202|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 53\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|664680|\n",
      "|     stand|614779|\n",
      "|stairsdown|505604|\n",
      "|      walk|715765|\n",
      "|  stairsup|564752|\n",
      "|      null|564099|\n",
      "|      bike|582998|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 54\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|676991|\n",
      "|     stand|626164|\n",
      "|stairsdown|514965|\n",
      "|      walk|729020|\n",
      "|  stairsup|575209|\n",
      "|      null|574544|\n",
      "|      bike|593795|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 55\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|689302|\n",
      "|     stand|637549|\n",
      "|stairsdown|524326|\n",
      "|      walk|742275|\n",
      "|  stairsup|585666|\n",
      "|      null|584989|\n",
      "|      bike|604592|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 56\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|701611|\n",
      "|     stand|648933|\n",
      "|stairsdown|533688|\n",
      "|      walk|755530|\n",
      "|  stairsup|596122|\n",
      "|      null|595437|\n",
      "|      bike|615389|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 57\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|713920|\n",
      "|     stand|660317|\n",
      "|stairsdown|543051|\n",
      "|      walk|768785|\n",
      "|  stairsup|606577|\n",
      "|      null|605886|\n",
      "|      bike|626185|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 58\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|726229|\n",
      "|     stand|671701|\n",
      "|stairsdown|552415|\n",
      "|      walk|782040|\n",
      "|  stairsup|617030|\n",
      "|      null|616336|\n",
      "|      bike|636981|\n",
      "+----------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 59\n",
      "-------------------------------------------\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|738536|\n",
      "|     stand|683088|\n",
      "|stairsdown|561777|\n",
      "|      walk|795296|\n",
      "|  stairsup|627486|\n",
      "|      null|626783|\n",
      "|      bike|647778|\n",
      "+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/21 14:44:28 ERROR WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7d26042 is aborting.\n",
      "21/08/21 14:44:28 ERROR WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7d26042 aborted.\n",
      "21/08/21 14:44:28 ERROR DiskBlockObjectWriter: Exception occurred while reverting partial writes to file /tmp/blockmgr-b3f2fd2c-b881-4de8-99da-2c05a5d44bd9/06/temp_shuffle_2969115e-8ccb-400e-ba9a-44358ab45f45, null\n",
      "21/08/21 14:44:28 ERROR DiskBlockObjectWriter: Exception occurred while reverting partial writes to file /tmp/blockmgr-b3f2fd2c-b881-4de8-99da-2c05a5d44bd9/37/temp_shuffle_b3287c95-21e2-45b1-abc9-52a1f250a61b, null\n",
      "21/08/21 14:44:28 ERROR DiskBlockObjectWriter: Exception occurred while reverting partial writes to file /tmp/blockmgr-b3f2fd2c-b881-4de8-99da-2c05a5d44bd9/30/temp_shuffle_0b3528b4-b9c8-4f3e-b0a4-fa19973f8b64, null\n",
      "21/08/21 14:44:28 ERROR DiskBlockObjectWriter: Exception occurred while reverting partial writes to file /tmp/blockmgr-b3f2fd2c-b881-4de8-99da-2c05a5d44bd9/27/temp_shuffle_a499dcc8-a1b6-42bf-b23c-d1be25f54c33, null\n",
      "21/08/21 14:44:28 ERROR DiskBlockObjectWriter: Exception occurred while reverting partial writes to file /tmp/blockmgr-b3f2fd2c-b881-4de8-99da-2c05a5d44bd9/03/temp_shuffle_11ff1e90-4c96-4734-84d7-70344f6274c6, null\n",
      "21/08/21 14:44:28 WARN TaskSetManager: Lost task 0.0 in stage 64.0 (TID 350) (0cadd86ac43f executor driver): TaskKilled (Stage cancelled)\n"
     ]
    }
   ],
   "source": [
    "# 기동\n",
    "activityQuery = activityTrigger.start()\n",
    "activityQuery.awaitTermination(30) # 노트북 특성상, 대기하면 다음 실행을 할 수 없으므로 30초만 수행하고 종료합니다\n",
    "activityQuery.stop() # 특정 타스크가 처리 중에 timeout 되는 경우, 해당 스레드가 종료되어 예외가 발생할 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 파일을 통한 스트리밍 시에 유의해야 할 특징 4가지\n",
    "* 하나. 모든 파일들의 포맷과 스키마는 동일해야 하며, 그렇지 않은 경우 쿼리의 실패로 이어지게 됩니다\n",
    "* 둘. 디렉토리 내의 파일 단위로 원자적으로 동작해야 하며, 한번에 정상적으로 읽어져야 합니다\n",
    "  - 즉, append 되고 있는 파일의 경우 문제가 될 수 있으며, update 혹은 append 되어서는 안 됩니다\n",
    "* 셋. 디렉토리 내의 새로운 파일들이 존재하더라도 모든 파일이 동시에 수행되지 않습니다\n",
    "  - 동시 수행 임계치에 따라 병렬로 수행되며, 정해진 순서를 보장하지 않습니다.\n",
    "  - maxFilesPerTrigger 옵션을 통해 처리율을 조정할 수 있습니다 - [프로그래밍 가이드](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#creating-streaming-dataframes-and-streaming-datasets)를 참고할 수 있습니다\n",
    "* 넷. 파일 쓰기는 append 모드만 지원하며, 이미 존재하는 파일에는 append 될 수 없습니다\n",
    "  - *end-to-end exatly-once gurantees* 지원은 _spark_metadata 경로에 존재하는 log 파일들을 통해 관리되어 가능하며, 종복 혹은 일부만 읽혀지는 경우는 없습니다. \n",
    "  - 만일 애플리케이션 재실행 시에 변경된 스키마로 데이터가 추가 되었다면, 쿼리 시에 해당 스키마가 조정되어야만 합니다\n",
    "  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>1. [중급]</font> 현재 생성된 스트리밍 애플리케이션을 처음부터 다시 수행해 보세요\n",
    "\n",
    "* 처음부터 다시 스트리밍 처리를 하기 위해서는 어떻게 해야하나요?\n",
    "  - 리눅스 삭제 명령 : `!rm -rf /path/to/remove`\n",
    "  - 체크포인트 위치 : /home/jovyan/work/lgde-spark-stream/tmp/activity_count\n",
    "  - 스트리밍 쓰기 객체 activityTrigger 는 실습 과정에서 정상적으로 생성되었다고 가정합니다\n",
    "\n",
    "* 현재 activityQuery 를 다시 수행하되 충분히 긴 시간동안 수행하여 오류 메시지가 발생하지 않도록 수행해 보세요\n",
    "  - 타임아웃 : 80초 이상\n",
    "  - 쿼리 실행 이후 애플리케이션을 반드시 종료해 주세요\n",
    "\n",
    "<details><summary>[정답] 출력 결과 확인 </summary>\n",
    "\n",
    "> 아래와 유사하게 방식으로 작성 되었다면 정답입니다\n",
    "\n",
    "```python\n",
    "# 아래에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n",
    "! rm -rf /home/jovyan/work/lgde-spark-stream/tmp/activity_count\n",
    "activityQuery = activityTrigger.start()\n",
    "activityQuery.awaitTermination(80)\n",
    "activityQuery.stop()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>2. [고급]</font> 스키마를 읽지 않고 직접 지정하는 코드를 작성해 보세요\n",
    "\n",
    "* [pyspark.sql.types.StructType](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html?highlight=structtype#pyspark.sql.types.StructType) 참고\n",
    "  - `customSchema = StructType([StructField(\"f1\", StringType(), True)])` 와 같은 형식으로 작성합니다\n",
    "\n",
    "* 기존에 작성된 코드를 활용하여 하나의 Cell 안에 작성해 보세요\n",
    "  - 타임아웃 : 10초 내외\n",
    "  - 쿼리 실행 이후 애플리케이션을 반드시 종료해 주세요\n",
    "\n",
    "<details><summary>[정답] 출력 결과 확인 </summary>\n",
    "\n",
    "> 아래와 유사하게 방식으로 작성 되었다면 정답입니다\n",
    "\n",
    "```python\n",
    "# 아래에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n",
    "customSchema = (\n",
    "    StructType()\n",
    "    .add(StructField(\"Arrival_Time\", LongType()))\n",
    "    .add(StructField(\"Creation_Time\", LongType()))\n",
    "    .add(StructField(\"Device\", StringType()))\n",
    "    .add(StructField(\"Index\", LongType()))\n",
    "    .add(StructField(\"Model\", StringType()))\n",
    "    .add(StructField(\"User\", StringType()))\n",
    "    .add(StructField(\"gt\", StringType()))\n",
    "    .add(StructField(\"x\", DoubleType()))\n",
    "    .add(StructField(\"y\", DoubleType()))\n",
    "    .add(StructField(\"z\", DoubleType()))\n",
    ")\n",
    "activityPath = f\"{work_data}/activity-data\"\n",
    "customReader = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .format(\"json\")\n",
    "    .schema(customSchema)\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .load(activityPath)\n",
    ")\n",
    "customCounter = (\n",
    "    customReader.groupBy(\"gt\").count()\n",
    ")\n",
    "queryName = \"custom_count\"\n",
    "customWriter = (\n",
    "    customCounter\n",
    "    .writeStream\n",
    "    .queryName(queryName)\n",
    "    .format(\"console\")\n",
    "    .outputMode(\"update\")\n",
    ")\n",
    "checkpointLocation = f\"{work_dir}/tmp/{queryName}\"\n",
    "!rm -rf $checkpointLocation\n",
    "customTrigger = (\n",
    "    customWriter\n",
    "    .trigger(processingTime=\"1 second\")\n",
    "    .option(\"checkpointLocation\", checkpointLocation)\n",
    ")\n",
    "customQuery = customTrigger.start()\n",
    "customQuery.awaitTermination(10)\n",
    "customQuery.stop()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>3. [고급]</font> 스트리밍 처리가 완료된 이후에 파일이 추가되면 어떻게 동작하나요?\n",
    "\n",
    "* 80초 이상 대기하여 카운트가 수렴한 시점에 data 경로 아래의 appended-1.json 파일을 수동으로 복사해 주고, 카운트에 변화가 있는지 확인합니다\n",
    "  - 타임아웃 : 180초 이상 (애플리케이션이 파일을 복사할 시간을 충분히 가질 수 있도록)\n",
    "  - 데이터 경로 : /home/jovyan/work/activity-data\n",
    "  - JSON 파일(\"part-00000-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json\")을 임의의 파일(appended-1.json\")로 변경하여 복사합니다\n",
    "\n",
    "<details><summary>[정답] 출력 결과 확인 </summary>\n",
    "\n",
    "> 아래와 유사하게 방식으로 작성 되었다면 정답입니다\n",
    "\n",
    "```python\n",
    "# 아래에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n",
    "\n",
    "! rm -rf /home/jovyan/work/lgde-spark-stream/tmp/activity_count\n",
    "activityQuery = activityWriter.start()\n",
    "activityQuery.awaitTermination(180)\n",
    "activityQuery.stop()\n",
    "\n",
    "# docker\n",
    "# $ cp /home/jovyan/work/data/activity-data/part-00000-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json /home/jovyan/work/data/activity-data/appended-1.json\n",
    "\n",
    "# 80초 이후 카운트가 수렴되었을 때에 json 파일 추가 시에 아래와 같이 카운트 수가 증가합니다\n",
    "notebook     | -------------------------------------------\n",
    "notebook     | Batch: 80\n",
    "notebook     | -------------------------------------------\n",
    "notebook     | +----------+-------+\n",
    "notebook     | |        gt|  count|\n",
    "notebook     | +----------+-------+\n",
    "notebook     | |       sit| 997023|\n",
    "notebook     | |     stand| 922167|\n",
    "notebook     | |stairsdown| 758424|\n",
    "notebook     | |      walk|1073658|\n",
    "notebook     | |      null| 846174|\n",
    "notebook     | |  stairsup| 847050|\n",
    "notebook     | |      bike| 874506|\n",
    "notebook     | +----------+-------+\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>4. [중급]</font> 애플리케이션이 종료된 이후에 파일이 추가된 경우, 애플리케이션을 재기동하면 어떻게 동작하나요?\n",
    "\n",
    "* 이전 예제에서 이미 애플리케이션이 종료었기 때문에, data 경로에 임의의 json 파일을 appended-2.json 으로| 수동으로 복사해 주고, 애플리케이션을 재기동하여 카운트에 변화가 있는지 확인합니다\n",
    "  - 타임아웃 : 10초 이상 (기동 이후에 확인할 정도의 시간)\n",
    "  - 데이터 경로 : /home/jovyan/work/activity-data\n",
    "  - JSON 파일(\"part-00000-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json\")을 임의의 파일(appended-2.json\")로 변경하여 복사합니다\n",
    "\n",
    "<details><summary>[정답] 출력 결과 확인 </summary>\n",
    "\n",
    "> 아래와 유사하게 방식으로 작성 되었다면 정답입니다. 파일 복사는 수동으로 진행해도 무관합니다\n",
    "\n",
    "```python\n",
    "# 아래에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n",
    "!cp \"$work_data/activity-data/part-00000-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json\" \"$work_data/activity-data/appended-2.json\"\n",
    "activityQuery = activityWriter.start()\n",
    "activityStatus = activityQuery.status\n",
    "activityQuery.awaitTermination(10) # 노트북 특성상, 대기하면 다음 실행을 할 수 없으므로 10초만 수행하고 종료합니다\n",
    "activityQuery.stop()\n",
    "    \n",
    "# 애플리케이션이 재기동 되었을 때에 추가된 json 파일 크기만큼 아래와 같이 카운트 수가 증가합니다\n",
    "notebook     | -------------------------------------------\n",
    "notebook     | Batch: 81\n",
    "notebook     | -------------------------------------------\n",
    "notebook     | +----------+-------+\n",
    "notebook     | |        gt|  count|\n",
    "notebook     | +----------+-------+\n",
    "notebook     | |       sit|1009332|\n",
    "notebook     | |     stand| 933551|\n",
    "notebook     | |stairsdown| 767789|\n",
    "notebook     | |      walk|1086914|\n",
    "notebook     | |      null| 856623|\n",
    "notebook     | |  stairsup| 857502|\n",
    "notebook     | |      bike| 885302|\n",
    "notebook     | +----------+-------+\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
