{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3일차 5교시 - Spark Bucketing\n",
    "> 스파크에서 버킷팅 기법이란 조인 혹은 집계 연산 시에 가장 성능을 떨어뜨리는 셔플을 피하기 위해 저장 시에 예상되는 파티션 그룹 키를 기반으로 미리 그룹핑 해서 저장해 두는 방법을 말합니다. spark.sql.sources.bucketing.enabled 를 통해 제어할 수 있고 기본 설정은 true 입니다. 결국 저장 시에 추가적인 고민과 시간이 필요하다는 의미이며, 그렇게 해서라도 충분히 리소스 사용을 상쇄할 수 있다고 판단되는 경우에만 사용하는 것을 추천 드립니다. Write Once Read Many 인 경우가 그러합니다.\n",
    "\n",
    "### 목차\n",
    "* [1. '버킷팅'이란?](#1.-'버킷팅'이란?)\n",
    "* [2. 언제 '버킷팅'을 적용하는가?](#2.-언제-'버킷팅'을-적용하는가?)\n",
    "* [3. '버킷팅' 다루기](#3.-'버킷팅'-다루기)\n",
    "\n",
    "### 참고자료\n",
    "  * https://luminousmen.com/post/the-5-minute-guide-to-using-bucketing-in-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/03 00:46:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cf89b3e9e8f0:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb730b75dc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from IPython.display import display, display_pretty, clear_output, JSON\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.sql.session.timeZone\", \"Asia/Seoul\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# 노트북에서 테이블 형태로 데이터 프레임 출력을 위한 설정을 합니다\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # display enabled\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 100) # display output columns size\n",
    "\n",
    "# 공통 데이터 위치\n",
    "home_jovyan = \"/home/jovyan\"\n",
    "work_data = f\"{home_jovyan}/work/data\"\n",
    "work_dir=!pwd\n",
    "work_dir = work_dir[0]\n",
    "\n",
    "# 로컬 환경 최적화\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5) # the number of partitions to use when shuffling data for joins or aggregations.\n",
    "spark.conf.set(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. '버킷팅'이란?\n",
    "> 하둡 기반의 파일 저장구조를 활용하는 스파크의 경우 세컨더리 인덱스 지원이 어렵기 때문에 '파티셔닝'을 통해 필터하는 것에는 한계가 있기 마련입니다. 이러한 문제를 해결하기 위해 버킷팅이라는 기법을 활용할 수 있는데, 특정 키와 파티션 수를 기준으로 대상 파티션 경로 내에 또 다른 파티션 파일 블록의 저장을 통해 읽기 성능을 최적화 시킬 수 있는데, 반드시 하이브/스파크 테이블 형태로만 저장된다는 점에 유의해야만 합니다.\n",
    "이는 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 언제 '버킷팅'을 적용하는가?\n",
    "* 디멘젼과 같은 누적 형식의 테이블의 경우 셔플이 발생하는 경우\n",
    "  * 조인 혹은 집계 대상이 되는 모든 데이터가 노드 간에 전달이 되기 때문에 네트워크 및 I/O 리소스를 많이 잡아 먹어 성능에 큰 영향을 미칩니다\n",
    "* 대용량 데이터의 셔플에 의한 익스큐터 노드의 저장데이터가 커지는 경우를 회피\n",
    "  * 익스큐터가 수행되는 노드의 임시 경로에 많은 데이터를 담게되므로 물리 노드에 부하를 주게되어 해당 노드에서 수행되는 다른 작업에도 영향이 있으며 클러스터 전체적인 성능 저하를 가져올 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. '버킷팅' 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. 그대로 저장 시에는 전체 셔플이 발생합니다.\n",
    "<!-- ![bucket1](images/bucket-1.png) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- make: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- engine_size: decimal(38,18) (nullable = true)\n",
      " |-- registration: string (nullable = true)\n",
      " |-- sale_price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 브로드캐스팅에 의해 혼란을 줄이기 위해 브로드캐스팅을 발생하지 않도록 강제합니다.\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "\n",
    "s1 = spark.read.parquet(\"source/t1\")\n",
    "s2 = spark.read.parquet(\"source/t2\")\n",
    "c12 = s1.join(s2, [s1.make == s2.make]).select(s1.make, s1.model, s1.engine_size, s1.registration, s2.sale_price)\n",
    "c12.printSchema()\n",
    "# mode(\"append\")\n",
    "# mode(\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|make         |count|\n",
      "+-------------+-----+\n",
      "|NISSAN       |5495 |\n",
      "|SKODA        |5495 |\n",
      "|MERCEDED_BENZ|5561 |\n",
      "|HYUNDAI      |5521 |\n",
      "|SUZUKI       |5628 |\n",
      "|KIA          |5495 |\n",
      "|VAUXHALL     |5696 |\n",
      "|FORD         |55579|\n",
      "|FIAT         |5530 |\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1.select(\"make\").groupBy(\"make\").count().show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 1000000\n"
     ]
    }
   ],
   "source": [
    "c1 = s1.count()\n",
    "c2 = s2.count()\n",
    "print(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [make#1, model#2, engine_size#3, registration#0, sale_price#11]\n",
      "+- *(5) SortMergeJoin [make#1], [make#8], Inner\n",
      "   :- *(2) Sort [make#1 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(make#1, 5), ENSURE_REQUIREMENTS, [id=#124]\n",
      "   :     +- *(1) Filter isnotnull(make#1)\n",
      "   :        +- *(1) ColumnarToRow\n",
      "   :           +- FileScan parquet [registration#0,make#1,model#2,engine_size#3] Batched: true, DataFilters: [isnotnull(make#1)], Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/lgde-spark-troubleshoot/source/t1], PartitionFilters: [], PushedFilters: [IsNotNull(make)], ReadSchema: struct<registration:string,make:string,model:string,engine_size:decimal(38,18)>\n",
      "   +- *(4) Sort [make#8 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(make#8, 5), ENSURE_REQUIREMENTS, [id=#133]\n",
      "         +- *(3) Filter isnotnull(make#8)\n",
      "            +- *(3) ColumnarToRow\n",
      "               +- FileScan parquet [make#8,sale_price#11] Batched: true, DataFilters: [isnotnull(make#8)], Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/lgde-spark-troubleshoot/source/t2], PartitionFilters: [], PushedFilters: [IsNotNull(make)], ReadSchema: struct<make:string,sale_price:double>\n",
      "\n",
      "\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "|   make|model|         engine_size|registration|sale_price|\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    2046.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    2688.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    3492.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    4723.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    3256.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    2011.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    5457.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    5151.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    4600.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    5373.0|\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "c12.explain()\n",
    "c12.where(\"make IN ('FORD', 'KIA', 'HYUNDAI') and sale_price > 2000.0\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. 파티션으로 저장 시에는 `Dynamic Partition Pruning` 활용이 가능하여 필터링이 가능합니다\n",
    "<!-- ![bucket2](images/bucket-2.png) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "s1.write.mode(\"overwrite\").partitionBy(\"make\").parquet(\"target/troubleshoot5/model\")\n",
    "s2.write.mode(\"overwrite\").partitionBy(\"make\").parquet(\"target/troubleshoot5/price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spark.read.parquet(\"target/troubleshoot5/model\")\n",
    "price = spark.read.parquet(\"target/troubleshoot5/price\")\n",
    "model_price = model.join(price, [model.make == price.make]).select(model.make, model.model, model.engine_size, model.registration, price.sale_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [make#106, model#104, engine_size#105, registration#103, sale_price#113]\n",
      "+- *(5) SortMergeJoin [make#106], [make#114], Inner\n",
      "   :- *(2) Sort [make#106 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(make#106, 5), ENSURE_REQUIREMENTS, [id=#274]\n",
      "   :     +- *(1) ColumnarToRow\n",
      "   :        +- FileScan parquet [registration#103,model#104,engine_size#105,make#106] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/lgde-spark-troubleshoot/target/troubleshoot5/model], PartitionFilters: [isnotnull(make#106)], PushedFilters: [], ReadSchema: struct<registration:string,model:string,engine_size:decimal(38,18)>\n",
      "   +- *(4) Sort [make#114 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(make#114, 5), ENSURE_REQUIREMENTS, [id=#282]\n",
      "         +- *(3) ColumnarToRow\n",
      "            +- FileScan parquet [sale_price#113,make#114] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/lgde-spark-troubleshoot/target/troubleshoot5/price], PartitionFilters: [isnotnull(make#114)], PushedFilters: [], ReadSchema: struct<sale_price:double>\n",
      "\n",
      "\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "|   make|model|         engine_size|registration|sale_price|\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "|HYUNDAI|  I20|1.700000000000000000|     PJn4bLy|    2827.0|\n",
      "|HYUNDAI|  I20|1.700000000000000000|     PJn4bLy|    4363.0|\n",
      "|HYUNDAI|  I20|1.700000000000000000|     PJn4bLy|    4754.0|\n",
      "|HYUNDAI|  I20|1.700000000000000000|     PJn4bLy|    4499.0|\n",
      "|HYUNDAI|  I20|1.700000000000000000|     PJn4bLy|    4597.0|\n",
      "|HYUNDAI|  I20|1.700000000000000000|     PJn4bLy|    4672.0|\n",
      "|HYUNDAI|  I20|1.700000000000000000|     PJn4bLy|    3657.0|\n",
      "|HYUNDAI|  I20|1.700000000000000000|     PJn4bLy|    2899.0|\n",
      "|HYUNDAI|  I20|1.700000000000000000|     PJn4bLy|    5130.0|\n",
      "|HYUNDAI|  I20|1.700000000000000000|     PJn4bLy|    2159.0|\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model_price.explain()\n",
    "model_price.where(\"make IN ('FORD', 'KIA', 'HYUNDAI') and sale_price > 2000.0\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. 버킷 저장 시에는 셔플이 발생하지 않습니다.\n",
    "<!-- ![bucket3](images/bucket-3.png) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numBuckets = 10\n",
    "spark.sql(\"drop table if exists model\")\n",
    "spark.sql(\"drop table if exists price\")\n",
    "\n",
    "# 이전에 삭제되지 않은 임시 경로가 있다면 삭제합니다.\n",
    "!rm -rf /home/jovyan/work/lgde-spark-troubleshoot/spark-warehouse/model\n",
    "!rm -rf /home/jovyan/work/lgde-spark-troubleshoot/spark-warehouse/price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "s1.write.mode(\"overwrite\").bucketBy(numBuckets, \"make\").sortBy(\"make\").saveAsTable(\"model\")\n",
    "s2.write.mode(\"overwrite\").bucketBy(numBuckets, \"make\").sortBy(\"make\").saveAsTable(\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = spark.sql(\"select * from model\")\n",
    "t2 = spark.sql(\"select * from price\")\n",
    "t12 = t1.join(t2, [t1.make == t2.make]).select(t1.make, t1.model, t1.engine_size, t1.registration, t2.sale_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [make#195, model#196, engine_size#197, registration#194, sale_price#205]\n",
      "+- *(3) SortMergeJoin [make#195], [make#202], Inner\n",
      "   :- *(1) Sort [make#195 ASC NULLS FIRST], false, 0\n",
      "   :  +- *(1) Filter isnotnull(make#195)\n",
      "   :     +- *(1) ColumnarToRow\n",
      "   :        +- FileScan parquet default.model[registration#194,make#195,model#196,engine_size#197] Batched: true, DataFilters: [isnotnull(make#195)], Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/lgde-spark-troubleshoot/spark-warehouse/model], PartitionFilters: [], PushedFilters: [IsNotNull(make)], ReadSchema: struct<registration:string,make:string,model:string,engine_size:decimal(38,18)>, SelectedBucketsCount: 10 out of 10\n",
      "   +- *(2) Sort [make#202 ASC NULLS FIRST], false, 0\n",
      "      +- *(2) Filter isnotnull(make#202)\n",
      "         +- *(2) ColumnarToRow\n",
      "            +- FileScan parquet default.price[make#202,sale_price#205] Batched: true, DataFilters: [isnotnull(make#202)], Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/lgde-spark-troubleshoot/spark-warehouse/price], PartitionFilters: [], PushedFilters: [IsNotNull(make)], ReadSchema: struct<make:string,sale_price:double>, SelectedBucketsCount: 10 out of 10\n",
      "\n",
      "\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "|   make|model|         engine_size|registration|sale_price|\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    2046.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    2688.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    3492.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    4723.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    3256.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    2011.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    5457.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    5151.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    4600.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    5373.0|\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "t12.explain()\n",
    "t12.where(\"make IN ('FORD', 'KIA', 'HYUNDAI') and sale_price > 2000.0\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
